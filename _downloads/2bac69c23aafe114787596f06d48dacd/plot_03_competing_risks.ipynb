{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Exploring the accuracy in time\n\nIn this notebook, we showcase how the accuracy in time metric is defined, behaves, and\nhow to interpret it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Definition of the Accuracy in Time\nHere is a little bit of context about this metric introduced in\n[Alberge et al. (2024)](https://hal.science/hal-04617672v4):\n\n- The accuracy in time is a generalization of the accuracy metric in the survival\n  and the competing risks setting, representing the proportion of correctly\n  predicted labels at a fixed time.\n- This metric is computed for different user-provided time horizons, specified\n  either as direct timestamps or quantiles of the observed durations.\n- For a given patient at a fixed time, we compare the actual observed event to\n  the most likely predicted one. For example, imagine a patient who experiences\n  death due to cancer at time $t$. Before this time, the model should predict\n  with the highest probability that the patient will survive. After $t$,\n  the model should predict the cancer-related death event with the highest\n  probability. Censored patients are excluded from the computation after their\n  censoring time.\n- The mathematical formula is:\n\n\\begin{align}\\mathrm{acc}(\\zeta) = \\frac{1}{n_{nc}} \\sum_{i=1}^n ~ I\\{\\hat{y}_i=y_{i,\\zeta}\\}\n       \\overline{I\\{\\delta_i = 0 \\cap t_i \\leq \\zeta \\}}\\end{align}\n\nwhere:\n\n- $I$ is the indicator function.\n- $\\zeta$ is a fixed time horizon.\n- $n_{nc}$ is the number of uncensored individuals at $\\zeta$.\n- $\\delta_i$ is the event experienced by the individual $i$ at\n  $t_i$.\n- $\\hat{y} = \\text{arg}\\max\\limits_{k \\in [0, K]} \\hat{F}_k(\\zeta|X=x_i)$\n  where $\\hat{F}_0(\\zeta|X=x_i) \\triangleq \\hat{S}(\\zeta|X=x_i)$.\n  $\\hat{y}$ is the most probable predicted event for individual $i$\n  at $\\zeta$.\n- $y_{i,\\zeta} = \\delta_i ~ I\\{t_i \\leq \\zeta \\}$ is the observed event\n  for individual $i$ at $\\zeta$.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage\n\n### Generating synthetic data\n\nWe begin by generating a linear, synthetic dataset. For each individual, we uniformly\nsample a shape and scale value, which we use to parameterize a Weibull distribution,\nfrom which we sample a duration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from hazardous.data import make_synthetic_competing_weibull\nfrom sklearn.model_selection import train_test_split\n\n\nX, y = make_synthetic_competing_weibull(n_events=3, n_samples=10_000, return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nX_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we display the distribution of our target.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\nfrom matplotlib import pyplot as plt\n\n\nsns.histplot(\n    y_test,\n    x=\"duration\",\n    hue=\"event\",\n    multiple=\"stack\",\n    palette=\"colorblind\",\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing the Accuracy in Time\n\nAfter training ``SurvivalBoost``, we compute its accuracy in time for 16 quantiles\nof the time grid, i.e. at 16 evenly-spaced times of observation \u2013$\\zeta$ in our\nformula above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom hazardous import SurvivalBoost\nfrom hazardous.metrics import accuracy_in_time\n\n\nresults = []\n\ntime_grid = np.arange(0, 4000, 100)\nsurv = SurvivalBoost(show_progressbar=False).fit(X_train, y_train)\ny_pred = surv.predict_cumulative_incidence(X_test, times=time_grid)\n\nquantiles = np.linspace(0.125, 1, 16)\naccuracy, taus = accuracy_in_time(y_test, y_pred, time_grid, quantiles=quantiles)\nresults.append(dict(model_name=\"Survival Boost\", accuracy=accuracy, taus=taus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also compute the accuracy in time of the Aalen-Johansen estimator, which is\na marginal model (it doesn't use covariates X), similar to the Kaplan-Meier estimator,\nexcept that it computes cumulative incidence functions of competing risks instead\nof a survival function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.interpolate import interp1d\nfrom lifelines import AalenJohansenFitter\nfrom hazardous.utils import check_y_survival\n\n\ndef predict_aalen_johansen(y_train, time_grid, n_sample_test):\n    event, duration = check_y_survival(y_train)\n    event_ids = sorted(set(event) - set([0]))\n\n    y_pred = []\n    for event_id in event_ids:\n        aj = AalenJohansenFitter(calculate_variance=False).fit(\n            durations=duration,\n            event_observed=event,\n            event_of_interest=event_id,\n        )\n        cif = aj.cumulative_density_\n        y_pred_ = interp1d(\n            x=cif.index,\n            y=cif[cif.columns[0]],\n            kind=\"linear\",\n            fill_value=\"extrapolate\",\n        )(time_grid)\n\n        y_pred.append(\n            # shape: (n_sample_test, 1, n_time_steps)\n            np.tile(y_pred_, (n_sample_test, 1, 1))\n        )\n\n    y_survival = (1 - np.sum(np.concatenate(y_pred, axis=1), axis=1))[:, None, :]\n    y_pred.insert(0, y_survival)\n\n    return np.concatenate(y_pred, axis=1)\n\n\ny_pred_aj = predict_aalen_johansen(y_train, time_grid, n_sample_test=X_test.shape[0])\n\naccuracy, taus = accuracy_in_time(y_test, y_pred_aj, time_grid, quantiles=quantiles)\nresults.append(dict(model_name=\"Aalan-Johansen\", accuracy=accuracy, taus=taus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results\n\nWe display the accuracy in time to compare SurvivalBoost with the Aalen-Johansen's\nestimator. Higher is better.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\n\nfig, ax = plt.subplots(figsize=(6, 3), dpi=300)\n\nresults = pd.DataFrame(results).explode(column=[\"accuracy\", \"taus\"])\n\nsns.lineplot(\n    results,\n    x=\"taus\",\n    y=\"accuracy\",\n    hue=\"model_name\",\n    ax=ax,\n    legend=False,\n)\n\nsns.scatterplot(\n    results,\n    x=\"taus\",\n    y=\"accuracy\",\n    hue=\"model_name\",\n    ax=ax,\n    s=50,\n    zorder=100,\n    style=\"model_name\",\n)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the accuracy is high at very beginning\n($t < 1000$), because both models predict that every individual survive, which\nis true in most cases. Then, beyond the time horizon 1000, the discriminative power\nof the conditional ``SurvivalBoost`` yields a better accuracy than the marginal,\nunbiased, Aalen-Johansen's estimator.\n\n### Understanding the accuracy in time\n\nWe can drill into this metric by counting the observed events cumulatively across\ntime, and compare that to predictions.\n\nWe display below the distribution of ground truth labels. Each color bar group\nrepresents the event distribution at some given time horizons.\nAlmost no individual have experienced an event at the very beginning (the very high\nblue bars, corresponding to censoring).\nThen, as time passes by, events occur and the number of censored individual at each\ntime horizon shrinks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_event_in_time(y_in_time, title):\n    event_in_times = []\n    for event_id in range(4):\n        event_in_times.append(\n            dict(\n                event_count=(y_in_time == event_id).sum(axis=0),\n                time_grid=time_grid,\n                event=event_id,\n            )\n        )\n\n    event_in_times = pd.DataFrame(event_in_times).explode([\"event_count\", \"time_grid\"])\n\n    ax = sns.barplot(\n        event_in_times,\n        x=\"time_grid\",\n        y=\"event_count\",\n        hue=\"event\",\n        palette=\"colorblind\",\n    )\n    ax.set_xticks(ax.get_xticks()[::10])\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Total events at $t$\")\n    ax.set_title(title)\n\n\ntime_grid_2d = np.tile(time_grid, (y_test.shape[0], 1))\nmask_event_happened = y_test[\"duration\"].values[:, None] <= time_grid_2d\ny_test_class = mask_event_happened * y_test[\"event\"].values[:, None]\n\n# In the same fashion as the accuracy-in-time, we don't count individual that were\n# censored in the past.\nmask_past_censoring = mask_event_happened * (y_test[\"event\"] == 0).values[:, None]\ny_test_class[mask_past_censoring] = -1\n\nplot_event_in_time(y_test_class, title=\"Ground truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we compare this ground truth to the classes predicted by ``SurvivalBoost``.\nInterestingly, it seems too confident about the censoring event at the\nbeginning ($t < 500$), but then becomes underconfident in the middle\n($t > 1500$) and very overconfident about the class 3 in the end\n($t > 3000$).\nOverall, we can see that the predicted labels gets closer to the ground truth as the\ntime progress, which correspond to the improvement of the accuracy in time\nwe saw for the large time horizons.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred_class = y_pred.argmax(axis=1)\ny_pred_class[mask_past_censoring] = -1\nplot_event_in_time(y_pred_class, title=\"Survival Boost\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we show the predicted classes from the Aalen-Johansen model.\nThese predictions remain constant across all individuals, as the model is marginal,\nand the global cumulative incidences are simply duplicated for each individual.\nOnce again, the changes in predicted labels align with the \"bumps\" observed in\nthe accuracy-over-time figure for the Aalen-Johansen model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred_class_aj = y_pred_aj.argmax(axis=1)\ny_pred_class_aj[mask_past_censoring] = -1\nplot_event_in_time(y_pred_class_aj, title=\"Aalen-Johansen\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}