{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Survival analysis with SurvivalBoost\n\nSurvival analysis is a time-to-event regression problem that deals with censored data.\nWe refer to individuals as censored if they did not experience the event during the\nperiod of observation.\n\nIn our setting, we are mostly interested in right-censored data, which means that the\nevent of interest did not occur before the end of the observation period (typically the\ntime of data collection).\n\nWe will use the The Molecular Taxonomy of Breast Cancer International Consortium\n(METABRIC) dataset as an example, which is available through ``pycox.datasets``. This\nis the processed data set used in the\n[DeepSurv paper (Katzman et al. 2018)](https://doi.org/10.1186/s12874-018-0482-1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\n\nfrom pycox.datasets import metabric\n\nnp.random.seed(0)\n\ndf = metabric.read_df()\nX = df.drop(columns=[\"event\", \"duration\"])\ny = df[[\"event\", \"duration\"]]\ny"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the target ``y`` is comprised of two columns:\n\n- ``event``, where $0$ marks censoring and $1$ is indicative that the\n  event of interest (death) has actually happened before the end of the\n  observation window.\n- ``duration``, the censored time-to-event $D = \\min(T, C) > 0$.\n  This is the minimum between the date of the experienced event, represented by the\n  random variable $T$, and the censoring date, represented by $C$.\n\nIn this dataset, approximately 42% of the data is censored..\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y[\"event\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using SurvivalBoost to estimate the survival function\n\nHere, our quantity of interest is the survival probability:\n\n\\begin{align}S(t | X=x) = P(T > t | X=x)\\end{align}\n\nThis represents the probability that an event doesn't occur at or before some\ngiven time $t$, i.e. that it happens at some time $T > t$,\ngiven the patient features $x$.\n\nSurvivalBoost is a scikit-learn compatible model which expects a covariates dataframe\n(or array-like) ``X``, and a target dataframe ``y`` with columns \"event\" and\n\"duration\". This allows SurvivalBoost to estimate the survival function $S$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from hazardous import SurvivalBoost\n\nsurvival_boost = SurvivalBoost(show_progressbar=False).fit(X_train, y_train)\n\nsurvival_boost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SurvivalBoost can then predict the survival function for each patient,\naccording to some time grid of horizons.\n**The time grid is learned during fit but can be passed during prediction**\nwith the parameter ``times``.\nWhen ``times`` is set to ``None``, the model will used the learned time grid.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predicted_curves = survival_boost.predict_cumulative_incidence(\n    X_test,\n    times=None,\n)\n\nsurvival_curves = predicted_curves[:, 0]  # survival function S(t)\nincidence_curves = predicted_curves[:, 1]  # cumulative incidence of the event (death)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the estimated survival function for some patients.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\npatient_ids_to_plot = [0, 1, 2, 3]\n\nfor idx in patient_ids_to_plot:\n    ax.plot(survival_boost.time_grid_, survival_curves[idx], label=f\"Patient {idx}\")\n\n    # plot symbols for death or censoring\n    event = y_test.iloc[idx][\"event\"]\n    duration = y_test.iloc[idx][\"duration\"]\n\n    # find the index of time closest to duration\n    jdx = np.searchsorted(survival_boost.time_grid_, duration)\n    smiley = \"\u2620\ufe0f\" if event == 1 else \"\u2716\"\n    ax.text(\n        duration,\n        survival_curves[idx, jdx],\n        smiley,\n        fontsize=20,\n        color=ax.lines[idx].get_color(),\n    )\n\nax.legend()\nax.set_title(\"\")\nax.set_xlabel(\"Months\")\nax.set_ylabel(\"Predicted Survival Probability\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measuring features impact on predictions\n\nWe can also observe the survival function by age group or by chemotherapy treatment\nto show the impact that the model attributes to these features. We do something akin\nto Partial Dependence Plots, where we sample the feature independently of the other\nfeatures to eliminate correlations.\n\nWe create a synthetic dataset where age (``x8``) is resampled to reduce\nconfounder bias.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_synthetic = X_train.copy()\n# Age varies from 20 to 80\nX_synthetic[\"x8\"] = np.linspace(20, 80, X_synthetic.shape[0])\n\n# Predict cumulative incidence on the synthetic dataset\nsurvival_curves_synthetic = survival_boost.predict_survival_function(X_synthetic)\n\n# Create age bins and sort them by the left bin edge\nage_bins = pd.cut(X_synthetic[\"x8\"], bins=[0, 30, 40, 50, 60, 70, 80, 90, 100])\nage_groups = sorted(age_bins.unique(), key=lambda x: x.left)\n\n# Create a colormap\nfig, ax = plt.subplots()\ncmap = plt.get_cmap(\"viridis\", len(age_groups))\n\nfor idx, age_group in enumerate(age_groups):\n    # Get the mask of patients in the current age group\n    mask = age_bins == age_group\n\n    # Calculate the mean and std cumulative incidence for the current age group\n    mean_survival = survival_curves_synthetic[mask].mean(axis=0)\n    std_survival = survival_curves_synthetic[mask].std(axis=0)\n\n    # Plot with color from colormap\n    ax.plot(\n        survival_boost.time_grid_,\n        mean_survival,\n        label=f\"Age {age_group}\",\n        color=cmap(idx),\n        linewidth=3,\n    )\n    # Add ribbon for std\n    ax.fill_between(\n        survival_boost.time_grid_,\n        mean_survival - std_survival,\n        mean_survival + std_survival,\n        color=cmap(idx),\n        alpha=0.3,\n    )\n\nax.legend()\nax.set_title(\"Survival function by age\")\nax.set_xlabel(\"Months\")\nax.set_ylabel(\"Estimated Survival Probability\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unsurprisingly, the cumulative incidence of death mostly increases with age.\nWe can do the same thing with chemotherapy treatement.\n\nLet's create a synthetic dataset where chemotherapy (``x6``)\nalternates between 0 and 1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_synthetic = X_train.copy()\nX_synthetic[\"x6\"] = np.tile([0, 1], X_synthetic.shape[0] // 2)\n\nsurvival_curves_synthetic = survival_boost.predict_survival_function(\n    X_synthetic,\n)\n\nfig, ax = plt.subplots()\ncmap = plt.get_cmap(\"viridis\", 2)\n\nfor chemo_group in [0, 1]:\n    mask = X_synthetic[\"x6\"] == chemo_group\n    mean_survival = survival_curves_synthetic[mask].mean(axis=0)\n    std_survival = survival_curves_synthetic[mask].std(axis=0)\n    ax.plot(\n        survival_boost.time_grid_,\n        mean_survival,\n        label=(\n            \"Treated with Chemotherapy\"\n            if chemo_group == 1\n            else \"Not Treated with Chemotherapy\"\n        ),\n        color=cmap(chemo_group),\n        linewidth=3,\n    )\n    ax.fill_between(\n        survival_boost.time_grid_,\n        mean_survival - std_survival,\n        mean_survival + std_survival,\n        color=cmap(chemo_group),\n        alpha=0.3,\n    )\n\nax.legend()\nax.set_title(\"Survival function by chemotherapy treatment\")\nax.set_xlabel(\"Months\")\nax.set_ylabel(\"Estimated Survival Probability\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "People treated with chemotherapy likely have more advanced stages of cancer, which is\nreflected by the lower estimated survival function. This serves as a reminder that\nthe estimate is not causal.\n\nLet's now attempt to quantify how well a survival curve estimated on a training set\nperforms on a test set.\n\n## Survival model evaluation\n\nThe Brier score and the C-index are measures that **assess the quality of a\npredicted survival curve** on a finite data sample.\n\n- **The Brier score in time is a strictly proper scoring rule**, which means that an\n  estimate of the survival probabilities at a given time $t$ has minimal Brier\n  score if and only if it matches the oracle survival probabilities induced by\n  the underlying data generating process. In that respect, the **Brier score**\n  assesses both the **calibration** and the **ranking power** of a survival\n  probability estimator. It is comprised between 0 and 1 (lower is better). It\n  answers the question *\"how close to the real probabilities are our estimates?\"*.\n\n- On the other hand, the **C-index** only assesses the **ranking power**: it\n  represents the probability that, for a randomly selected pair of patients,\n  the patient with the higher estimated survival probability will survive\n  longer than the other. It is comprised between 0 and 1 (higher is better),\n  with 0.5 corresponding to random predictions.\n\n.. dropdown:: Mathematical formulation (Brier score)\n\n    .. math::\n\n        \\mathrm{BS}^c(t) = \\frac{1}{n} \\sum_{i=1}^n I(d_i \\leq t \\cap \\delta_i = 1)\n        \\frac{(0 - \\hat{S}(t | \\mathbf{x}_i))^2}{\\hat{G}(d_i)} + I(d_i > t)\n        \\frac{(1 - \\hat{S}(t | \\mathbf{x}_i))^2}{\\hat{G}(t)}\n\n    In the survival analysis context, the Brier Score can be seen as the Mean\n    Squared Error (MSE) between our probability $\\hat{S}(t)$ and our\n    target label $\\delta_i \\in {0, 1}$, weighted by the inverse probability\n    of censoring $\\frac{1}{\\hat{G}(t)}$.\n    In practice we estimate $\\hat{G}(t)$ using a variant of\n    the Kaplan-Estimator with swapped event indicator.\n\n    - When no event or censoring has happened at $t$ yet, i.e.\n      $I(d_i > t)$, we penalize a low probability of survival with\n      $(1 - \\hat{S}(t|\\mathbf{x}_i))^2$.\n    - Conversely, when an individual has experienced an event before $t$, i.e.\n      $I(d_i \\leq t \\cap \\delta_i = 1)$, we penalize a high probability\n      of survival with $(0 - \\hat{S}(t|\\mathbf{x}_i))^2$.\n\n.. dropdown:: Mathematical formulation (Harrell's C-index)\n\n    .. math::\n\n        \\mathrm{C_{index}} = \\frac{\\sum_{i,j} I(d_i < d_j \\space \\cap \\space\n        \\delta_i = 1 \\space \\cap \\space \\mu_i < \\mu_j)}\n        {\\sum_{i,j} I(d_i < d_j \\space \\cap \\space \\delta_i = 1)}\n\n    where $\\mu_i$ and $\\mu_j$ are the time-averaged predicted survival\n    probabilities for individual $i$ and $j$.\n\nAdditionnaly, we compute the Integrated Brier Score (IBS), which we will use to\nsummarize the Brier score in time:\n\n\\begin{align}\\mathrm{IBS} = \\frac{1}{t_{max} - t_{min}}\\int^{t_{max}}_{t_{min}}\n    \\mathrm{BS(t)} dt\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from hazardous.metrics import integrated_brier_score_survival\n\nibs_survboost = integrated_brier_score_survival(\n    y_train,\n    y_test,\n    survival_curves,\n    times=survival_boost.time_grid_,\n)\nprint(f\"IBS for SurvivalBoost: {ibs_survboost:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare this to the Integrated Brier score of a simple Kaplan-Meier estimator,\nwhich doesn't take the patient features into account.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lifelines import KaplanMeierFitter\n\nkm_model = KaplanMeierFitter()\nkm_model.fit(y[\"duration\"], y[\"event\"])\nsurvival_curve_agg_km = km_model.survival_function_at_times(\n    survival_boost.time_grid_,\n)\n\n# To get individual survival curves, we duplicate the survival curve for each patient.\nsurvival_curves_km = np.tile(survival_curve_agg_km, (X_test.shape[0], 1))\n\nibs_km = integrated_brier_score_survival(\n    y_train,\n    y_test,\n    survival_curves_km,\n    times=survival_boost.time_grid_,\n)\nprint(f\"IBS for Kaplan-Meier: {ibs_km:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also compute the concordance index for both the Kaplan-Meier and SurvivalBoost.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lifelines.utils import concordance_index\n\nconcordance_index_km = concordance_index(\n    event_observed=y_test[\"event\"],\n    event_times=y_test[\"duration\"],\n    predicted_scores=survival_curves_km.mean(axis=1),\n)\nprint(f\"Concordance index for Kaplan-Meier: {concordance_index_km:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "0.5 corresponds to random chance, which makes sense as the Kaplan-Meier estimator\ndoesn't depend on the patient features.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "concordance_index_survboost = concordance_index(\n    event_observed=y_test[\"event\"],\n    event_times=y_test[\"duration\"],\n    predicted_scores=survival_curves.mean(axis=1),\n)\nprint(f\"Concordance index for SurvivalBoost: {concordance_index_survboost:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}